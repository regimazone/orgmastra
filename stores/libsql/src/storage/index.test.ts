import { randomUUID } from 'crypto';
import {
  createSampleEval,
  createSampleTraceForDB,
  createSampleThread,
  createTestSuite,
  createSampleMessageV1,
  resetRole,
  createSampleMessageV2,
  createSampleEpisode,
} from '@internal/storage-test-utils';
import type { MastraMessageV1, MastraMessageV2, StorageThreadType } from '@mastra/core';
import { Mastra } from '@mastra/core/mastra';
import { TABLE_EVALS, TABLE_TRACES, TABLE_MESSAGES, TABLE_THREADS, TABLE_EPISODES } from '@mastra/core/storage';
import { describe, it, expect, beforeAll, beforeEach } from 'vitest';

import { LibSQLStore } from './index';

const TEST_DB_URL = 'file::memory:?cache=shared';

const libsql = new LibSQLStore({
  url: TEST_DB_URL,
});
const mastra = new Mastra({
  storage: libsql,
});

createTestSuite(mastra.getStorage()!);

describe('LibSQLStore Pagination Features', () => {
  let store: LibSQLStore;

  beforeAll(async () => {
    store = libsql;
  });

  beforeEach(async () => {
    await store.clearTable({ tableName: TABLE_EVALS });
    await store.clearTable({ tableName: TABLE_TRACES });
    await store.clearTable({ tableName: TABLE_MESSAGES });
    await store.clearTable({ tableName: TABLE_THREADS });
  });

  describe('getEvals with pagination', () => {
    it('should return paginated evals with total count (page/perPage)', async () => {
      const agentName = 'libsql-pagination-agent-evals';
      const evalRecords = Array.from({ length: 25 }, (_, i) => createSampleEval(agentName, i % 2 === 0));
      await store.batchInsert({ tableName: TABLE_EVALS, records: evalRecords.map(r => r as any) });

      const page1 = await store.getEvals({ agentName, page: 0, perPage: 10 });
      expect(page1.evals).toHaveLength(10);
      expect(page1.total).toBe(25);
      expect(page1.page).toBe(0);
      expect(page1.perPage).toBe(10);
      expect(page1.hasMore).toBe(true);

      const page3 = await store.getEvals({ agentName, page: 2, perPage: 10 });
      expect(page3.evals).toHaveLength(5);
      expect(page3.total).toBe(25);
      expect(page3.page).toBe(2);
      expect(page3.hasMore).toBe(false);
    });

    it('should support limit/offset pagination for getEvals', async () => {
      const agentName = 'libsql-pagination-lo-evals';
      const evalRecords = Array.from({ length: 15 }, () => createSampleEval(agentName));
      await store.batchInsert({ tableName: TABLE_EVALS, records: evalRecords.map(r => r as any) });

      const result = await store.getEvals({ agentName, page: 2, perPage: 5 });
      expect(result.evals).toHaveLength(5);
      expect(result.total).toBe(15);
      expect(result.page).toBe(2);
      expect(result.perPage).toBe(5);
      expect(result.hasMore).toBe(false);
    });

    it('should filter by type with pagination for getEvals', async () => {
      const agentName = 'libsql-pagination-type-evals';
      const testEvals = Array.from({ length: 10 }, () => createSampleEval(agentName, true));
      const liveEvals = Array.from({ length: 8 }, () => createSampleEval(agentName, false));
      await store.batchInsert({ tableName: TABLE_EVALS, records: [...testEvals, ...liveEvals].map(r => r as any) });

      const testResults = await store.getEvals({ agentName, type: 'test', page: 0, perPage: 5 });
      expect(testResults.evals).toHaveLength(5);
      expect(testResults.total).toBe(10);

      const liveResults = await store.getEvals({ agentName, type: 'live', page: 1, perPage: 3 });
      expect(liveResults.evals).toHaveLength(3);
      expect(liveResults.total).toBe(8);
      expect(liveResults.hasMore).toBe(true);
    });

    it('should filter by date with pagination for getEvals', async () => {
      const agentName = 'libsql-pagination-date-evals';
      const now = new Date();
      const yesterday = new Date(now.getTime() - 24 * 60 * 60 * 1000);
      const dayBeforeYesterday = new Date(now.getTime() - 48 * 60 * 60 * 1000);

      const recordsToInsert = [
        createSampleEval(agentName, false, dayBeforeYesterday),
        createSampleEval(agentName, false, dayBeforeYesterday),
        createSampleEval(agentName, false, yesterday),
        createSampleEval(agentName, false, yesterday),
        createSampleEval(agentName, false, now),
        createSampleEval(agentName, false, now),
      ];
      await store.batchInsert({ tableName: TABLE_EVALS, records: recordsToInsert.map(r => r as any) });

      const fromYesterday = await store.getEvals({ agentName, dateRange: { start: yesterday }, page: 0, perPage: 3 });
      expect(fromYesterday.total).toBe(4);
      expect(fromYesterday.evals).toHaveLength(3); // Should get 2 from 'now', 1 from 'yesterday' due to DESC order and limit 3
      fromYesterday.evals.forEach(e =>
        expect(new Date(e.createdAt).getTime()).toBeGreaterThanOrEqual(new Date(yesterday.toISOString()).getTime()),
      );
      // Check if the first item is from 'now' if possible (because of DESC order)
      if (fromYesterday.evals.length > 0) {
        expect(new Date(fromYesterday.evals[0].createdAt).toISOString().slice(0, 10)).toEqual(
          now.toISOString().slice(0, 10),
        );
      }

      const onlyDayBefore = await store.getEvals({
        agentName,
        dateRange: { end: new Date(yesterday.getTime() - 1) },
        page: 0,
        perPage: 5,
      });
      expect(onlyDayBefore.total).toBe(2);
      expect(onlyDayBefore.evals).toHaveLength(2);
    });
  });

  describe('getTraces with pagination', () => {
    it('should return paginated traces with total count when returnPaginationResults is true', async () => {
      const scope = 'libsql-test-scope-traces';
      const traceRecords = Array.from({ length: 18 }, (_, i) => createSampleTraceForDB(`test-trace-${i}`, scope));
      await store.batchInsert({ tableName: TABLE_TRACES, records: traceRecords.map(r => r as any) });

      const page1 = await store.getTracesPaginated({
        scope,
        page: 0,
        perPage: 8,
      });
      expect(page1.traces).toHaveLength(8);
      expect(page1.total).toBe(18);
      expect(page1.page).toBe(0);
      expect(page1.perPage).toBe(8);
      expect(page1.hasMore).toBe(true);

      const page3 = await store.getTracesPaginated({
        scope,
        page: 2,
        perPage: 8,
      });
      expect(page3.traces).toHaveLength(2);
      expect(page3.total).toBe(18);
      expect(page3.hasMore).toBe(false);
    });

    it('should return an array of traces when returnPaginationResults is undefined', async () => {
      const scope = 'libsql-array-traces';
      const traceRecords = [createSampleTraceForDB('trace-arr-1', scope), createSampleTraceForDB('trace-arr-2', scope)];
      await store.batchInsert({ tableName: TABLE_TRACES, records: traceRecords.map(r => r as any) });

      const tracesUndefined = await store.getTraces({
        scope,
        page: 0,
        perPage: 5,
      });
      expect(Array.isArray(tracesUndefined)).toBe(true);
      expect(tracesUndefined.length).toBe(2);
      // @ts-expect-error
      expect(tracesUndefined.total).toBeUndefined();
    });

    it('should filter by attributes with pagination for getTraces', async () => {
      const scope = 'libsql-attr-traces';
      const tracesWithAttr = Array.from({ length: 8 }, (_, i) =>
        createSampleTraceForDB(`trace-prod-${i}`, scope, { environment: 'prod' }),
      );
      const tracesWithoutAttr = Array.from({ length: 5 }, (_, i) =>
        createSampleTraceForDB(`trace-dev-${i}`, scope, { environment: 'dev' }),
      );
      await store.batchInsert({
        tableName: TABLE_TRACES,
        records: [...tracesWithAttr, ...tracesWithoutAttr].map(r => r as any),
      });

      const prodTraces = await store.getTracesPaginated({
        scope,
        attributes: { environment: 'prod' },
        page: 0,
        perPage: 5,
      });
      expect(prodTraces.traces).toHaveLength(5);
      expect(prodTraces.total).toBe(8);
      expect(prodTraces.hasMore).toBe(true);
    });

    it('should filter by date with pagination for getTraces', async () => {
      const scope = 'libsql-date-traces';
      const now = new Date();
      const yesterday = new Date(now.getTime() - 24 * 60 * 60 * 1000);
      const dayBeforeYesterday = new Date(now.getTime() - 48 * 60 * 60 * 1000);

      const recordsToInsert = [
        createSampleTraceForDB('t_dbf1', scope, undefined, dayBeforeYesterday),
        createSampleTraceForDB('t_dbf2', scope, undefined, dayBeforeYesterday),
        createSampleTraceForDB('t_y1', scope, undefined, yesterday),
        createSampleTraceForDB('t_y3', scope, undefined, yesterday),
        createSampleTraceForDB('t_n1', scope, undefined, now),
        createSampleTraceForDB('t_n2', scope, undefined, now),
      ];
      await store.batchInsert({ tableName: TABLE_TRACES, records: recordsToInsert.map(r => r as any) });

      const fromYesterday = await store.getTracesPaginated({
        scope,
        dateRange: { start: yesterday },
        page: 0,
        perPage: 3,
      });
      expect(fromYesterday.total).toBe(4);
      expect(fromYesterday.traces).toHaveLength(3);
      fromYesterday.traces.forEach(t =>
        expect(new Date(t.createdAt).getTime()).toBeGreaterThanOrEqual(new Date(yesterday.toISOString()).getTime()),
      );
      if (fromYesterday.traces.length > 0 && fromYesterday.traces[0].createdAt === now.toISOString()) {
        expect(new Date(fromYesterday.traces[0].createdAt).toISOString().slice(0, 10)).toEqual(
          now.toISOString().slice(0, 10),
        );
      }

      const onlyNow = await store.getTracesPaginated({
        scope,
        dateRange: { start: now, end: now },
        page: 0,
        perPage: 5,
      });
      expect(onlyNow.total).toBe(2);
      expect(onlyNow.traces).toHaveLength(2);
      onlyNow.traces.forEach(t =>
        expect(new Date(t.createdAt).toISOString().slice(0, 10)).toEqual(now.toISOString().slice(0, 10)),
      );
    });
  });

  describe('getMessages with pagination', () => {
    it('should return paginated messages with total count', async () => {
      resetRole();
      const threadData = createSampleThread();
      threadData.resourceId = 'resource-msg-pagination';
      const thread = await store.saveThread({ thread: threadData as StorageThreadType });

      const messageRecords: MastraMessageV1[] = [];
      for (let i = 0; i < 15; i++) {
        messageRecords.push(createSampleMessageV1({ threadId: thread.id, content: `Message ${i + 1}` }));
      }
      await store.saveMessages({ messages: messageRecords });

      const page1 = await store.getMessagesPaginated({
        threadId: thread.id,
        selectBy: { pagination: { page: 0, perPage: 5 } },
        format: 'v1',
      });
      expect(page1.messages).toHaveLength(5);
      expect(page1.total).toBe(15);
      expect(page1.page).toBe(0);
      expect(page1.perPage).toBe(5);
      expect(page1.hasMore).toBe(true);

      const page3 = await store.getMessagesPaginated({
        threadId: thread.id,
        selectBy: { pagination: { page: 2, perPage: 5 } },
        format: 'v1',
      });
      expect(page3.messages).toHaveLength(5);
      expect(page3.total).toBe(15);
      expect(page3.hasMore).toBe(false);
    });

    it('should filter by date with pagination for getMessages', async () => {
      const threadData = createSampleThread();
      const thread = await store.saveThread({ thread: threadData as StorageThreadType });
      const now = new Date();
      const yesterday = new Date(
        now.getFullYear(),
        now.getMonth(),
        now.getDate() - 1,
        now.getHours(),
        now.getMinutes(),
        now.getSeconds(),
      );
      const dayBeforeYesterday = new Date(
        now.getFullYear(),
        now.getMonth(),
        now.getDate() - 2,
        now.getHours(),
        now.getMinutes(),
        now.getSeconds(),
      );

      // Ensure timestamps are distinct for reliable sorting by creating them with a slight delay for testing clarity
      const messagesToSave: MastraMessageV1[] = [];
      messagesToSave.push(
        createSampleMessageV1({ threadId: thread.id, content: 'Message 1', createdAt: dayBeforeYesterday }),
      );
      await new Promise(r => setTimeout(r, 5));
      messagesToSave.push(
        createSampleMessageV1({ threadId: thread.id, content: 'Message 2', createdAt: dayBeforeYesterday }),
      );
      await new Promise(r => setTimeout(r, 5));
      messagesToSave.push(createSampleMessageV1({ threadId: thread.id, content: 'Message 3', createdAt: yesterday }));
      await new Promise(r => setTimeout(r, 5));
      messagesToSave.push(createSampleMessageV1({ threadId: thread.id, content: 'Message 4', createdAt: yesterday }));
      await new Promise(r => setTimeout(r, 5));
      messagesToSave.push(createSampleMessageV1({ threadId: thread.id, content: 'Message 5', createdAt: now }));
      await new Promise(r => setTimeout(r, 5));
      messagesToSave.push(createSampleMessageV1({ threadId: thread.id, content: 'Message 6', createdAt: now }));

      await store.saveMessages({ messages: messagesToSave, format: 'v1' });
      // Total 6 messages: 2 now, 2 yesterday, 2 dayBeforeYesterday (oldest to newest)

      const fromYesterday = await store.getMessagesPaginated({
        threadId: thread.id,
        selectBy: { pagination: { page: 0, perPage: 3, dateRange: { start: yesterday } } },
        format: 'v2',
      });
      expect(fromYesterday.total).toBe(4);
      expect(fromYesterday.messages).toHaveLength(3);
      const firstMessageTime = new Date((fromYesterday.messages[0] as MastraMessageV1).createdAt).getTime();
      expect(firstMessageTime).toBeGreaterThanOrEqual(new Date(yesterday.toISOString()).getTime());
      if (fromYesterday.messages.length > 0) {
        expect(new Date((fromYesterday.messages[0] as MastraMessageV1).createdAt).toISOString().slice(0, 10)).toEqual(
          yesterday.toISOString().slice(0, 10),
        );
      }
    });
  });

  describe('getThreadsByResourceId with pagination', () => {
    it('should return paginated threads with total count', async () => {
      const resourceId = `libsql-paginated-resource-${randomUUID()}`;
      const threadRecords: StorageThreadType[] = [];
      for (let i = 0; i < 17; i++) {
        const threadData = createSampleThread();
        threadData.resourceId = resourceId;
        threadRecords.push(threadData as StorageThreadType);
      }
      for (const tr of threadRecords) {
        await store.saveThread({ thread: tr });
      }

      const page1 = await store.getThreadsByResourceIdPaginated({ resourceId, page: 0, perPage: 7 });
      expect(page1.threads).toHaveLength(7);
      expect(page1.total).toBe(17);
      expect(page1.page).toBe(0);
      expect(page1.perPage).toBe(7);
      expect(page1.hasMore).toBe(true);

      const page3 = await store.getThreadsByResourceIdPaginated({ resourceId, page: 2, perPage: 7 });
      expect(page3.threads).toHaveLength(3);
      expect(page3.total).toBe(17);
      expect(page3.hasMore).toBe(false);
    });
  });
});

describe('LibSQLStore updateMessages', () => {
  let store: LibSQLStore;
  let thread: StorageThreadType;

  beforeAll(async () => {
    store = libsql;
  });

  beforeEach(async () => {
    await store.clearTable({ tableName: TABLE_MESSAGES });
    await store.clearTable({ tableName: TABLE_THREADS });
    const threadData = createSampleThread();
    thread = await store.saveThread({ thread: threadData as StorageThreadType });
  });

  it('should update a single field of a message (e.g., role)', async () => {
    const originalMessage = createSampleMessageV2({ threadId: thread.id, role: 'user' });
    await store.saveMessages({ messages: [originalMessage], format: 'v2' });

    const updatedMessages = await store.updateMessages({
      messages: [{ id: originalMessage.id, role: 'assistant' }],
    });

    expect(updatedMessages).toHaveLength(1);
    expect(updatedMessages[0].role).toBe('assistant');

    const fromDb = await store.getMessages({ threadId: thread.id, format: 'v2' });
    expect(fromDb[0].role).toBe('assistant');
  });

  it('should update only the metadata within the content field, preserving other content fields', async () => {
    const originalMessage = createSampleMessageV2({
      threadId: thread.id,
      content: { content: 'hello world', parts: [{ type: 'text', text: 'hello world' }] },
    });
    await store.saveMessages({ messages: [originalMessage], format: 'v2' });

    const newMetadata = { someKey: 'someValue' };
    await store.updateMessages({
      messages: [{ id: originalMessage.id, content: { metadata: newMetadata } as any }],
    });

    const fromDb = await store.getMessages({ threadId: thread.id, format: 'v2' });
    expect(fromDb).toHaveLength(1);
    expect(fromDb[0].content.metadata).toEqual(newMetadata);
    expect(fromDb[0].content.content).toBe('hello world');
    expect(fromDb[0].content.parts).toEqual([{ type: 'text', text: 'hello world' }]);
  });

  it('should update only the content string within the content field, preserving metadata', async () => {
    const originalMessage = createSampleMessageV2({
      threadId: thread.id,
      content: { metadata: { initial: true } },
    });
    await store.saveMessages({ messages: [originalMessage], format: 'v2' });

    const newContentString = 'This is the new content string';
    await store.updateMessages({
      messages: [{ id: originalMessage.id, content: { content: newContentString } as any }],
    });

    const fromDb = await store.getMessages({ threadId: thread.id, format: 'v2' });
    expect(fromDb[0].content.content).toBe(newContentString);
    expect(fromDb[0].content.metadata).toEqual({ initial: true });
  });

  it('should deep merge metadata, not overwrite it', async () => {
    const originalMessage = createSampleMessageV2({
      threadId: thread.id,
      content: { metadata: { initial: true }, content: 'old content' },
    });
    await store.saveMessages({ messages: [originalMessage], format: 'v2' });

    const newMetadata = { updated: true };
    await store.updateMessages({
      messages: [{ id: originalMessage.id, content: { metadata: newMetadata } as any }],
    });

    const fromDb = await store.getMessages({ threadId: thread.id, format: 'v2' });
    expect(fromDb[0].content.content).toBe('old content');
    expect(fromDb[0].content.metadata).toEqual({ initial: true, updated: true });
  });

  it('should update multiple messages at once', async () => {
    const msg1 = createSampleMessageV2({ threadId: thread.id, role: 'user' });
    const msg2 = createSampleMessageV2({ threadId: thread.id, content: { content: 'original' } });
    await store.saveMessages({ messages: [msg1, msg2], format: 'v2' });

    await store.updateMessages({
      messages: [
        { id: msg1.id, role: 'assistant' },
        { id: msg2.id, content: { content: 'updated' } as any },
      ],
    });

    const fromDb = await store.getMessages({ threadId: thread.id, format: 'v2' });
    const updatedMsg1 = fromDb.find(m => m.id === msg1.id)!;
    const updatedMsg2 = fromDb.find(m => m.id === msg2.id)!;

    expect(updatedMsg1.role).toBe('assistant');
    expect(updatedMsg2.content.content).toBe('updated');
  });

  it('should update the parent thread updatedAt timestamp', async () => {
    const originalMessage = createSampleMessageV2({ threadId: thread.id });
    await store.saveMessages({ messages: [originalMessage], format: 'v2' });
    const initialThread = await store.getThreadById({ threadId: thread.id });

    await new Promise(r => setTimeout(r, 10));

    await store.updateMessages({ messages: [{ id: originalMessage.id, role: 'assistant' }] });

    const updatedThread = await store.getThreadById({ threadId: thread.id });

    expect(new Date(updatedThread!.updatedAt).getTime()).toBeGreaterThan(new Date(initialThread!.updatedAt).getTime());
  });

  it('should update timestamps on both threads when moving a message', async () => {
    const thread2 = await store.saveThread({ thread: createSampleThread() });
    const message = createSampleMessageV2({ threadId: thread.id });
    await store.saveMessages({ messages: [message], format: 'v2' });

    const initialThread1 = await store.getThreadById({ threadId: thread.id });
    const initialThread2 = await store.getThreadById({ threadId: thread2.id });

    await new Promise(r => setTimeout(r, 10));

    await store.updateMessages({
      messages: [{ id: message.id, threadId: thread2.id }],
    });

    const updatedThread1 = await store.getThreadById({ threadId: thread.id });
    const updatedThread2 = await store.getThreadById({ threadId: thread2.id });

    expect(new Date(updatedThread1!.updatedAt).getTime()).toBeGreaterThan(
      new Date(initialThread1!.updatedAt).getTime(),
    );
    expect(new Date(updatedThread2!.updatedAt).getTime()).toBeGreaterThan(
      new Date(initialThread2!.updatedAt).getTime(),
    );

    // Verify the message was moved
    const thread1Messages = await store.getMessages({ threadId: thread.id, format: 'v2' });
    const thread2Messages = await store.getMessages({ threadId: thread2.id, format: 'v2' });
    expect(thread1Messages).toHaveLength(0);
    expect(thread2Messages).toHaveLength(1);
    expect(thread2Messages[0].id).toBe(message.id);
  });

  it('should not fail when trying to update a non-existent message', async () => {
    const originalMessage = createSampleMessageV2({ threadId: thread.id });
    await store.saveMessages({ messages: [originalMessage], format: 'v2' });

    await expect(
      store.updateMessages({
        messages: [{ id: randomUUID(), role: 'assistant' }],
      }),
    ).resolves.not.toThrow();

    const fromDb = await store.getMessages({ threadId: thread.id, format: 'v2' });
    expect(fromDb[0].role).toBe(originalMessage.role);
  });
});

describe('LibSQLStore Double-nesting Prevention', () => {
  let store: LibSQLStore;

  beforeAll(async () => {
    store = libsql;
  });

  beforeEach(async () => {
    await store.clearTable({ tableName: TABLE_MESSAGES });
    await store.clearTable({ tableName: TABLE_THREADS });
  });

  it('should handle stringified JSON content without double-nesting', async () => {
    const threadData = createSampleThread();
    const thread = await store.saveThread({ thread: threadData as StorageThreadType });

    // Simulate user passing stringified JSON as message content (like the original bug report)
    const stringifiedContent = JSON.stringify({ userInput: 'test data', metadata: { key: 'value' } });
    const message: MastraMessageV2 = {
      id: `msg-${randomUUID()}`,
      role: 'user',
      threadId: thread.id,
      resourceId: thread.resourceId,
      content: {
        format: 2,
        parts: [{ type: 'text', text: stringifiedContent }],
        content: stringifiedContent, // This is the stringified JSON that user passed
      },
      createdAt: new Date(),
    };

    // Save the message - this should stringify the whole content object for storage
    await store.saveMessages({ messages: [message], format: 'v2' });

    // Retrieve the message - this is where double-nesting could occur
    const retrievedMessages = await store.getMessages({ threadId: thread.id, format: 'v2' });
    expect(retrievedMessages).toHaveLength(1);

    const retrievedMessage = retrievedMessages[0] as MastraMessageV2;

    // Check that content is properly structured as a V2 message
    expect(typeof retrievedMessage.content).toBe('object');
    expect(retrievedMessage.content.format).toBe(2);

    // CRITICAL: The content.content should still be the original stringified JSON
    // NOT double-nested like: { content: '{"format":2,"parts":[...],"content":"{\\"userInput\\":\\"test data\\"}"}' }
    expect(retrievedMessage.content.content).toBe(stringifiedContent);

    // Verify the content can be parsed as the original JSON
    const parsedContent = JSON.parse(retrievedMessage.content.content as string);
    expect(parsedContent).toEqual({ userInput: 'test data', metadata: { key: 'value' } });

    // Additional check: ensure the message doesn't have the "Found unhandled message" structure
    expect(retrievedMessage.content.parts).toBeDefined();
    expect(Array.isArray(retrievedMessage.content.parts)).toBe(true);
  });
});

describe('LibSQLStore Episode Features', () => {
  let store: LibSQLStore;

  beforeAll(async () => {
    store = libsql;
  });

  beforeEach(async () => {
    await store.clearTable({ tableName: TABLE_EPISODES });
  });

  describe('Episode JSON serialization', () => {
    it('should properly serialize and deserialize array fields', async () => {
      const episode = createSampleEpisode();
      episode.categories = ['work', 'important', 'milestone'];
      episode.messageIds = ['msg-1', 'msg-2', 'msg-3'];
      episode.relatedEpisodeIds = ['ep-1', 'ep-2'];
      
      await store.saveEpisode({ episode });
      
      const retrieved = await store.getEpisodeById({ id: episode.id });
      expect(retrieved).toBeTruthy();
      expect(Array.isArray(retrieved!.categories)).toBe(true);
      expect(retrieved!.categories).toEqual(['work', 'important', 'milestone']);
      expect(Array.isArray(retrieved!.messageIds)).toBe(true);
      expect(retrieved!.messageIds).toEqual(['msg-1', 'msg-2', 'msg-3']);
      expect(Array.isArray(retrieved!.relatedEpisodeIds)).toBe(true);
      expect(retrieved!.relatedEpisodeIds).toEqual(['ep-1', 'ep-2']);
    });

    it('should handle empty arrays correctly', async () => {
      const episode = createSampleEpisode();
      episode.categories = [];
      episode.messageIds = [];
      episode.relatedEpisodeIds = [];
      
      await store.saveEpisode({ episode });
      
      const retrieved = await store.getEpisodeById({ id: episode.id });
      expect(retrieved!.categories).toEqual([]);
      expect(retrieved!.messageIds).toEqual([]);
      expect(retrieved!.relatedEpisodeIds).toEqual([]);
    });

    it('should properly serialize metadata field', async () => {
      const episode = createSampleEpisode();
      episode.metadata = {
        complex: {
          nested: {
            data: 'value',
            array: [1, 2, 3],
          },
        },
        timestamp: new Date().toISOString(),
      };
      
      await store.saveEpisode({ episode });
      
      const retrieved = await store.getEpisodeById({ id: episode.id });
      expect(retrieved!.metadata).toEqual(episode.metadata);
    });
  });

  describe('Category management in resource metadata', () => {
    it('should create resource with categories when first episode is saved', async () => {
      const resourceId = `resource-${randomUUID()}`;
      const episode = createSampleEpisode({ resourceId });
      episode.categories = ['work', 'project'];
      
      await store.saveEpisode({ episode });
      
      // Check resource was created with categories
      const resource = await store.getResourceById({ resourceId });
      expect(resource).toBeTruthy();
      expect(resource!.metadata?.episodeCategories).toBeTruthy();
      expect(resource!.metadata.episodeCategories).toContain('work');
      expect(resource!.metadata.episodeCategories).toContain('project');
    });

    it('should update resource categories when new categories are added', async () => {
      const resourceId = `resource-${randomUUID()}`;
      
      // Save first episode
      const episode1 = createSampleEpisode({ resourceId });
      episode1.categories = ['work', 'meeting'];
      await store.saveEpisode({ episode: episode1 });
      
      // Save second episode with new categories
      const episode2 = createSampleEpisode({ resourceId });
      episode2.categories = ['personal', 'meeting']; // 'meeting' is duplicate
      await store.saveEpisode({ episode: episode2 });
      
      // Check categories are properly merged
      const categories = await store.getCategoriesForResource({ resourceId });
      expect(categories).toContain('work');
      expect(categories).toContain('meeting');
      expect(categories).toContain('personal');
      expect(categories).toHaveLength(3); // No duplicates
    });

    it('should update resource categories when episode is updated', async () => {
      const resourceId = `resource-${randomUUID()}`;
      const episode = createSampleEpisode({ resourceId });
      episode.categories = ['work'];
      
      await store.saveEpisode({ episode });
      
      // Update episode with new categories
      await store.updateEpisode({
        id: episode.id,
        updates: { categories: ['personal', 'health'] },
      });
      
      // Check categories were updated
      const categories = await store.getCategoriesForResource({ resourceId });
      expect(categories).toContain('work'); // Original still there
      expect(categories).toContain('personal');
      expect(categories).toContain('health');
    });
  });

  describe('Episode update error handling', () => {
    it('should throw error when updating non-existent episode', async () => {
      const nonExistentId = `episode-${randomUUID()}`;
      
      await expect(
        store.updateEpisode({
          id: nonExistentId,
          updates: { title: 'New Title' },
        })
      ).rejects.toThrow('EPISODE_NOT_FOUND');
    });
  });

  describe('Episode ordering', () => {
    it('should return episodes ordered by createdAt descending', async () => {
      const resourceId = `resource-${randomUUID()}`;
      const dates = [
        new Date('2024-01-01'),
        new Date('2024-01-03'),
        new Date('2024-01-02'),
      ];
      
      const episodes = dates.map((date, i) => 
        createSampleEpisode({ 
          resourceId, 
          date,
          id: `episode-${i}`,
        })
      );
      
      // Save in random order
      for (const episode of episodes) {
        await store.saveEpisode({ episode });
      }
      
      // Get episodes - should be ordered by createdAt desc
      const retrieved = await store.getEpisodesByResourceId({ resourceId });
      expect(retrieved).toHaveLength(3);
      expect(retrieved[0].id).toBe('episode-1'); // Jan 3
      expect(retrieved[1].id).toBe('episode-2'); // Jan 2
      expect(retrieved[2].id).toBe('episode-0'); // Jan 1
    });
  });

  describe('Episode filtering by category', () => {
    it('should handle case-sensitive category filtering', async () => {
      const resourceId = `resource-${randomUUID()}`;
      const episode = createSampleEpisode({ resourceId });
      episode.categories = ['Work', 'IMPORTANT', 'MileStone'];
      
      await store.saveEpisode({ episode });
      
      // Exact case match
      const workEpisodes = await store.getEpisodesByCategory({ resourceId, category: 'Work' });
      expect(workEpisodes).toHaveLength(1);
      
      // Different case - should not match
      const workLowercase = await store.getEpisodesByCategory({ resourceId, category: 'work' });
      expect(workLowercase).toHaveLength(0);
    });

    it('should filter episodes with JSON_EACH correctly', async () => {
      const resourceId = `resource-${randomUUID()}`;
      
      // Create episodes with overlapping categories
      const episodes = [
        createSampleEpisode({ resourceId }),
        createSampleEpisode({ resourceId }),
        createSampleEpisode({ resourceId }),
      ];
      
      episodes[0].categories = ['alpha', 'beta'];
      episodes[1].categories = ['beta', 'gamma'];
      episodes[2].categories = ['gamma', 'delta'];
      
      for (const episode of episodes) {
        await store.saveEpisode({ episode });
      }
      
      // Test each category
      const alphaEpisodes = await store.getEpisodesByCategory({ resourceId, category: 'alpha' });
      expect(alphaEpisodes).toHaveLength(1);
      
      const betaEpisodes = await store.getEpisodesByCategory({ resourceId, category: 'beta' });
      expect(betaEpisodes).toHaveLength(2);
      
      const gammaEpisodes = await store.getEpisodesByCategory({ resourceId, category: 'gamma' });
      expect(gammaEpisodes).toHaveLength(2);
      
      const deltaEpisodes = await store.getEpisodesByCategory({ resourceId, category: 'delta' });
      expect(deltaEpisodes).toHaveLength(1);
    });
  });
});
